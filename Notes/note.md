信息增益比：

- 通过条件熵的计算公式，又可以推测出，如果某一个**属性**的取值越多，那么这个条件熵的值就会越小。从而，采用 IG 最大法选择构建决策，可以理解成选择取值较多的属性。

- **特征熵**记为${SplitInfo= -\sum_i{p(v_i)}log_2{p(v_i)}}$，



选分裂的值：

- （删掉了引用的部分）



Gini系数

- 这样一可以进一步简化基尼系数的计算，（删掉后面的部分）



CART分类树

- 删掉（但求的是Gini系数，不是IG）



剪枝-得到子树序列

- C(T)为训练集的预测误差（如Gini系数）删掉括号内容
- 在$T_0$上剪去$g(t)$最小的$T_t$ -> 在$T_0$上剪去$g(t)$最小的以t的根节点的子树

